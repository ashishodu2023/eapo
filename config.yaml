model_id: "TinyLlama/TinyLlama-1.1B-Chat-v1.0"
quantization: "none"
device_map: "auto"            # keep "auto" here
attn_implementation: "eager"  # Phi-3 needs eager (no SDPA)
bnb_compute_dtype: "auto"


max_new_tokens: 128
do_sample: false
temperature: 0.0
top_p: 1.0

dataset_path: "data/xsum_sample.jsonl"
num_trials: 20
energy_weight: 1.0
accuracy_weight: 1.0
tpj_weight: 1.0
eval_batch: 6
nvml_interval_ms: 50
seed: 42


num_trials: 1

# instead of searching, evaluate exactly this prompt config on your whole dataset
fixed_prompt:
  style: role
  reasoning: bounded
  format: bullets
  brevity: word50